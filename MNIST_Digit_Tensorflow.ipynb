{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Digit_Tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWUoyfkLqE2M0/OxtufoTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73efdc4e853646b986dc087a0118e6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_176ebf8eb4cf478ca50d2224576fb167",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5289ef89cf3d4c5ca1b0391e9143319f",
              "IPY_MODEL_1f834b17fb914d6e9d2d826db570b665"
            ]
          }
        },
        "176ebf8eb4cf478ca50d2224576fb167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5289ef89cf3d4c5ca1b0391e9143319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1cb8c96a0264f479d8a89854e5bf68c",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6750f20f8c254eba893a4c9b42ad2d1c"
          }
        },
        "1f834b17fb914d6e9d2d826db570b665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baedc96143014ce4af60c61c52b1e0b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:01&lt;00:00,  2.10 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a3462f3acb84746917e1cd6041a4bc3"
          }
        },
        "b1cb8c96a0264f479d8a89854e5bf68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6750f20f8c254eba893a4c9b42ad2d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baedc96143014ce4af60c61c52b1e0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a3462f3acb84746917e1cd6041a4bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trivendrakulhare/TensorFlow_MNIST/blob/master/MNIST_Digit_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsuKThgXjyaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Neural Network for MNIST Classification\n",
        "# The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). 60_000 Training data and 10_000 testing data\n",
        "# The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes.\n",
        "#Our goal would be to build a neural network with 2 hidden layers."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HeP_AEtj3-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import the relevant packages\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# TensorFLow includes a data provider for MNIST that we'll use.\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbJ_Qc8Rj4Ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "73efdc4e853646b986dc087a0118e6a6",
            "176ebf8eb4cf478ca50d2224576fb167",
            "5289ef89cf3d4c5ca1b0391e9143319f",
            "1f834b17fb914d6e9d2d826db570b665",
            "b1cb8c96a0264f479d8a89854e5bf68c",
            "6750f20f8c254eba893a4c9b42ad2d1c",
            "baedc96143014ce4af60c61c52b1e0b5",
            "8a3462f3acb84746917e1cd6041a4bc3"
          ]
        },
        "outputId": "94459c7a-b628-43a0-a04a-24de3d9e19d0"
      },
      "source": [
        "# mnist_dataset = tfds.load() loads the data.\n",
        "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "# with_info=True will also provide us with a tuple containing information about the version, features, number of samples\n",
        "# as_supervised=True will load the dataset in a 2-tuple structure (input, target) \n",
        "\n",
        "# extracting the training and testing dataset\n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
        "\n",
        "#Here we split the validation dataset from training dataset.\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "#casting this number to an integer, as a float may cause an error along the way\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "# store the number of test samples in a dedicated variable \n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "\n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
        "\n",
        "# Defining a function called: scale, that will take an MNIST image and its label\n",
        "def scale(image, label):\n",
        "   \n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # since the possible values for the inputs are 0 to 255 (256 different shades of grey)\n",
        "    # if we divide each element by 255, we would get the desired result -> all elements will be between 0 and 1 \n",
        "    image /= 255.\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# the method .map() allows us to apply a custom transformation to a given dataset\n",
        "# we have already decided that we will get the validation data from mnist_train, so \n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "\n",
        "# finally, we scale and batch the test data\n",
        "# we scale it so it has the same magnitude as the train and validation\n",
        "# there is no need to shuffle it, because we won't be training on the test data\n",
        "# there would be a single batch, equal to the size of the test data\n",
        "test_data = mnist_test.map(scale)\n",
        "\n",
        "\n",
        "# let's also shuffle the data\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "# this BUFFER_SIZE parameter is here for cases when we're dealing with enormous datasets\n",
        "# then we can't shuffle the whole dataset in one go because we can't fit it all in memory\n",
        "# so instead TF only stores BUFFER_SIZE samples in memory at a time and shuffles them\n",
        "\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
        "\n",
        "\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "\n",
        "# similarly, the train_data is everything else, so we skip as many samples as there are in the validation dataset\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
        "\n",
        "# determine the batch size\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "# batching train data would help us to iterate over the different batches\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "\n",
        "# batch the test data\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "\n",
        "\n",
        "# takes next batch (it is the only batch)\n",
        "# because as_supervized=True, we've got a 2-tuple structure\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73efdc4e853646b986dc087a0118e6a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Dl Completed...', max=4, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDUdfHbxj4Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Outline the model\n",
        "\n",
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 50\n",
        "    \n",
        "# define how the model will look like\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    # the first layer (the input layer)\n",
        "    # each observation is 28x28x1 pixels, therefore it is a tensor of rank 3\n",
        "    # since we don't know CNNs yet, we don't know how to feed such input into our net, so we must flatten the images\n",
        "  \n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n",
        "    \n",
        "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
        "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "    \n",
        "    # the final layer is no different, we just make sure to activate it with softmax\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iEhX8o7j4O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we define the optimizer we'd like to use, \n",
        "# the loss function, \n",
        "# and the metrics we are interested in obtaining at each iteration\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa5zq_WEj4V4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6d950a12-d073-44ba-94e9-b7fae8ece7c2"
      },
      "source": [
        "# Determine the maximum number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# we fit the model, specifying the\n",
        "# training data\n",
        "# the total number of epochs\n",
        "# and the validation data we just created ourselves in the format: (inputs,targets)\n",
        "STEPS = num_validation_samples/ BATCH_SIZE\n",
        "model.fit(train_data, epochs=NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), validation_steps = STEPS, verbose =2)#"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1080/1080 - 14s - loss: 0.3526 - accuracy: 0.8964 - val_loss: 0.1894 - val_accuracy: 0.9432\n",
            "Epoch 2/5\n",
            "1080/1080 - 15s - loss: 0.1613 - accuracy: 0.9520 - val_loss: 0.1496 - val_accuracy: 0.9560\n",
            "Epoch 3/5\n",
            "1080/1080 - 15s - loss: 0.1233 - accuracy: 0.9637 - val_loss: 0.1440 - val_accuracy: 0.9580\n",
            "Epoch 4/5\n",
            "1080/1080 - 15s - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.1339 - val_accuracy: 0.9607\n",
            "Epoch 5/5\n",
            "1080/1080 - 14s - loss: 0.0846 - accuracy: 0.9742 - val_loss: 0.1264 - val_accuracy: 0.9622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68df4b0f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmiVvEXPj4bZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8418720-72c1-4985-9949-ac2a465bf982"
      },
      "source": [
        "# Test the model\n",
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47cS35Qaj4hY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c286317-adf3-4ccc-aadd-7526945ff7d0"
      },
      "source": [
        "# Printing test loss and test accuracy\n",
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.12. Test accuracy: 96.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdJLVx5Lj4n0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BATjltYGj4TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uwg0xyhXl1S1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}